{"cells": [{"cell_type": "markdown", "metadata": {}, "source": "# Pandas in Google Colab \u2014 2\u2011Hour Hands\u2011On Tutorial (with **tips** dataset)\n\n**Last updated:** 2025-08-13\n\nWelcome! In this guided session you'll learn and practise the pandas workflow end\u2011to\u2011end using the classic **tips** dataset.\n\n### What you'll learn\n- What pandas is and where it shines\n- Importing data from URLs/files and first look\n- Core manipulation (select, filter, sort, compute new columns)\n- Cleaning & preprocessing (types, renaming, text ops, duplicates)\n- Handling missing data (detect, drop, fill, groupwise fill, interpolate)\n- Analysis & visualization (stats, histograms, boxplots, scatter, bars)\n- Grouping, aggregations & joins/merges\n- Reshaping (pivot, melt, stack/unstack)\n\n> \u23f1 **Time plan (~120 minutes)**  \n> 0) Setup & load (10m)  \n> 1) Import & manipulate (20m)  \n> 2) Clean & preprocess (15m)  \n> 3) Missing data (15m)  \n> 4) Analysis & viz (20m)  \n> 5) Group & merge (20m)  \n> 6) Reshape & pivot (15m)  \n> 7) Mini\u2011project + wrap\u2011up (5m)\n\n**How to use this notebook**\n- Run each cell top\u2011to\u2011bottom. Read the notes, then complete the **Exercises** marked with \u2705.\n- Use the **Solution** cells AFTER attempting the exercise."}, {"cell_type": "markdown", "metadata": {}, "source": "---\n## 0) Setup & Load the **tips** dataset (10m)\n\nWe'll use the public copy of `tips.csv` hosted in the seaborn-data repo."}, {"cell_type": "code", "metadata": {}, "source": "# Install/Import (Colab usually has these preinstalled)\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n# Display options (feel free to tweak)\npd.set_option('display.max_rows', 10)\npd.set_option('display.precision', 3)\n\n# Load the tips dataset from GitHub (works in Colab)\nurl = \"https://raw.githubusercontent.com/mwaskom/seaborn-data/master/tips.csv\"\ntips = pd.read_csv(url)\n\n# Quick peek\ntips.head()", "outputs": [], "execution_count": null}, {"cell_type": "code", "metadata": {}, "source": "# Basic metadata\nprint(\"Shape:\", tips.shape)\nprint(\"\\nInfo:\")\nprint(tips.info())\nprint(\"\\nDescribe:\")\ndisplay(tips.describe(include='all'))", "outputs": [], "execution_count": null}, {"cell_type": "markdown", "metadata": {}, "source": "**Columns overview**  \n- `total_bill` (float): total bill in USD  \n- `tip` (float): tip amount in USD  \n- `sex` (category-like string): sex of bill payer  \n- `smoker` (string): \"Yes\"/\"No\"  \n- `day` (string): day of week (Thur, Fri, Sat, Sun)  \n- `time` (string): Lunch/Dinner  \n- `size` (int): party size"}, {"cell_type": "markdown", "metadata": {}, "source": "### \u2705 Exercise 0\n1. Print unique values for `day` and `time`.  \n2. How many duplicate rows exist?  \n3. Compute the average `total_bill` and `tip`."}, {"cell_type": "code", "metadata": {}, "source": "# YOUR WORK: Exercise 0\n# 1) Unique values\n# print(\"Unique days:\", ...)\n# print(\"Unique time:\", ...)\n\n# 2) Duplicates\n# print(\"Duplicates:\", ...)\n\n# 3) Averages\n# print(\"Avg total_bill:\", ...)\n# print(\"Avg tip:\", ...)", "outputs": [], "execution_count": null}, {"cell_type": "code", "metadata": {}, "source": "# Solution: Exercise 0\nprint(\"Unique days:\", tips['day'].unique())\nprint(\"Unique time:\", tips['time'].unique())\nprint(\"Duplicates:\", tips.duplicated().sum())\nprint(\"Avg total_bill:\", tips['total_bill'].mean())\nprint(\"Avg tip:\", tips['tip'].mean())", "outputs": [], "execution_count": null}, {"cell_type": "markdown", "metadata": {}, "source": "---\n## 1) Data import & core manipulation (20m)\n\nWe'll cover:\n- Selecting rows/columns (`[]`, `.loc`, `.iloc`)\n- Filtering (boolean masks, `.query`)\n- Sorting (`.sort_values`)\n- Creating new columns (`.assign` or direct assignment)"}, {"cell_type": "code", "metadata": {}, "source": "# Column selection\ntips[['total_bill', 'tip']].head()", "outputs": [], "execution_count": null}, {"cell_type": "code", "metadata": {}, "source": "# Row selection by integer position\ntips.iloc[0:5]  # first 5 rows", "outputs": [], "execution_count": null}, {"cell_type": "code", "metadata": {}, "source": "# Row/column selection by labels (example)\ntips.loc[tips['day']=='Sun', ['total_bill','tip','size']].head()", "outputs": [], "execution_count": null}, {"cell_type": "code", "metadata": {}, "source": "# Filtering with boolean masks\nbig_tables = tips[tips['size'] >= 5]\nbig_tables.head()", "outputs": [], "execution_count": null}, {"cell_type": "code", "metadata": {}, "source": "# Filtering with query (nice for readability)\nlunch_smokers = tips.query(\"time == 'Lunch' and smoker == 'Yes'\")\nlunch_smokers.head()", "outputs": [], "execution_count": null}, {"cell_type": "code", "metadata": {}, "source": "# Sorting\ntips_sorted = tips.sort_values(by=['total_bill', 'tip'], ascending=[False, True])\ntips_sorted.head()", "outputs": [], "execution_count": null}, {"cell_type": "code", "metadata": {}, "source": "# New columns: tip percentage and per-person tip\ntips = tips.assign(\n    tip_pct = tips['tip'] / tips['total_bill'],\n    tip_per_person = tips['tip'] / tips['size']\n)\ntips.head()", "outputs": [], "execution_count": null}, {"cell_type": "markdown", "metadata": {}, "source": "### \u2705 Exercise 1\n1. Filter rows where `day` is **Sat** and `size` \u2265 3.  \n2. Among those, create a new column `bill_per_person = total_bill / size`.  \n3. Sort the result by `bill_per_person` descending and show top 5."}, {"cell_type": "code", "metadata": {}, "source": "# YOUR WORK: Exercise 1\n# sat3 = ...\n# sat3 = sat3.assign(bill_per_person = ...)\n# sat3_sorted = ...\n# sat3_sorted.head()", "outputs": [], "execution_count": null}, {"cell_type": "code", "metadata": {}, "source": "# Solution: Exercise 1\nsat3 = tips[(tips['day']=='Sat') & (tips['size']>=3)]\nsat3 = sat3.assign(bill_per_person = sat3['total_bill']/sat3['size'])\nsat3_sorted = sat3.sort_values('bill_per_person', ascending=False)\nsat3_sorted.head()", "outputs": [], "execution_count": null}, {"cell_type": "markdown", "metadata": {}, "source": "---\n## 2) Cleaning & preprocessing (15m)\n\nWe'll look at:\n- Data types (`.dtypes`, `.astype`)\n- Renaming columns (`.rename`)\n- String fixes (case, trim)\n- Removing duplicates (`.drop_duplicates`)"}, {"cell_type": "code", "metadata": {}, "source": "# Data types\ntips.dtypes", "outputs": [], "execution_count": null}, {"cell_type": "code", "metadata": {}, "source": "# Cast text columns to 'category' for memory/performance (optional)\ntips['sex'] = tips['sex'].astype('category')\ntips['smoker'] = tips['smoker'].astype('category')\ntips['day'] = tips['day'].astype('category')\ntips['time'] = tips['time'].astype('category')\ntips.dtypes", "outputs": [], "execution_count": null}, {"cell_type": "code", "metadata": {}, "source": "# Rename columns to snake_case\ntips = tips.rename(columns={'total_bill':'total_bill', 'tip':'tip', 'tip_pct':'tip_pct',\n                            'tip_per_person':'tip_per_person'})  # already clean, just demo", "outputs": [], "execution_count": null}, {"cell_type": "code", "metadata": {}, "source": "# Simulate a messy string column and clean it\ntips['server_name'] = [' Alice ', 'Bob', 'ALICE', 'bob', ' Alice ', 'Bob'] * (len(tips)//6) + ['Alice']*(len(tips)%6)\ntips['server_name'] = tips['server_name'].str.strip().str.title()\ntips['server_name'].head()", "outputs": [], "execution_count": null}, {"cell_type": "code", "metadata": {}, "source": "# Remove duplicates (demo: make duplicates then drop)\ndemo = tips.copy()\ndemo = pd.concat([demo, demo.iloc[0:2]], ignore_index=True)  # add 2 duplicate rows\nprint(\"Before drop_duplicates:\", demo.shape)\ndemo = demo.drop_duplicates()\nprint(\"After drop_duplicates:\", demo.shape)", "outputs": [], "execution_count": null}, {"cell_type": "markdown", "metadata": {}, "source": "### \u2705 Exercise 2\n1. Ensure `size` is of type `int64`. If not, cast it.  \n2. Create a clean copy `tips_clean` keeping only columns: `total_bill, tip, tip_pct, tip_per_person, sex, smoker, day, time, size`.  \n3. Verify there are **no** duplicates in `tips_clean`."}, {"cell_type": "code", "metadata": {}, "source": "# YOUR WORK: Exercise 2\n# tips['size'] = ...\n# tips_clean = tips[[...]].copy()\n# print(\"Duplicates in tips_clean:\", ...)", "outputs": [], "execution_count": null}, {"cell_type": "code", "metadata": {}, "source": "# Solution: Exercise 2\ntips['size'] = tips['size'].astype('int64')\ntips_clean = tips[['total_bill','tip','tip_pct','tip_per_person','sex','smoker','day','time','size']].copy()\nprint(\"Duplicates in tips_clean:\", tips_clean.duplicated().sum())", "outputs": [], "execution_count": null}, {"cell_type": "markdown", "metadata": {}, "source": "---\n## 3) Handling missing data (15m)\n\nThe original `tips` has no NaNs. We'll **inject** some missingness to learn:\n- Detecting missing (`.isna()`/`.isnull()`)\n- Dropping (`.dropna()`)\n- Filling (`.fillna()`), including groupwise fills\n- Interpolating (`.interpolate()`)"}, {"cell_type": "code", "metadata": {}, "source": "# Create a copy with missing values\nrng = np.random.default_rng(42)\ntips_na = tips_clean.copy()\nmask = rng.choice([True, False], size=len(tips_na), p=[0.1, 0.9])\ntips_na.loc[mask, 'tip'] = np.nan  # inject ~10% NaNs in 'tip'\ntips_na.loc[mask, 'size'] = np.nan # inject NaNs in 'size' as well\n\ntips_na.isna().sum()", "outputs": [], "execution_count": null}, {"cell_type": "code", "metadata": {}, "source": "# Drop rows with any NaNs (demo)\ndropped = tips_na.dropna()\ndropped.shape", "outputs": [], "execution_count": null}, {"cell_type": "code", "metadata": {}, "source": "# Simple fills\nfilled_const = tips_na.fillna({'tip': tips_na['tip'].median(), 'size': tips_na['size'].median()})\nfilled_const.isna().sum()", "outputs": [], "execution_count": null}, {"cell_type": "code", "metadata": {}, "source": "# Groupwise fill: fill 'tip' NaNs with group ('day','time') median tip\ntips_group_fill = tips_na.copy()\ntips_group_fill['tip'] = tips_group_fill.groupby(['day','time'])['tip'].transform(lambda s: s.fillna(s.median()))\ntips_group_fill.isna().sum()", "outputs": [], "execution_count": null}, {"cell_type": "code", "metadata": {}, "source": "# Interpolate numeric columns linearly (note: order matters; this is just demo)\ntips_interp = tips_na.sort_values('total_bill').interpolate(numeric_only=True)\ntips_interp.isna().sum()", "outputs": [], "execution_count": null}, {"cell_type": "markdown", "metadata": {}, "source": "### \u2705 Exercise 3\n1. From `tips_na`, drop only rows where **both** `tip` and `size` are missing, keep others.  \n2. For remaining NaNs in `size`, fill with the **rounded mean size per `day`**.  \n3. Verify no NaNs remain."}, {"cell_type": "code", "metadata": {}, "source": "# YOUR WORK: Exercise 3\n# step1 = ...\n# step2 = ...\n# step2.isna().sum()", "outputs": [], "execution_count": null}, {"cell_type": "code", "metadata": {}, "source": "# Solution: Exercise 3\nstep1 = tips_na[~(tips_na['tip'].isna() & tips_na['size'].isna())].copy()\nmean_size_by_day = step1.groupby('day')['size'].transform('mean').round()\nstep2 = step1.copy()\nstep2['size'] = step2['size'].fillna(mean_size_by_day)\nstep2.isna().sum()", "outputs": [], "execution_count": null}, {"cell_type": "markdown", "metadata": {}, "source": "---\n## 4) Analysis & Visualization (20m)\n\nWe'll compute quick stats and build a few plots with **matplotlib** (no seaborn).  \nEach chart uses its own code cell."}, {"cell_type": "code", "metadata": {}, "source": "# Descriptive stats\nprint(\"Overall tip %:\", (tips['tip'].sum()/tips['total_bill'].sum()).round(3))\nprint(\"\\nCounts by day:\")\nprint(tips['day'].value_counts())\n\nprint(\"\\nSmoker ratio by time:\")\nprint((tips.groupby('time')['smoker'].value_counts(normalize=True)*100).round(1))", "outputs": [], "execution_count": null}, {"cell_type": "code", "metadata": {}, "source": "# Histogram of total_bill\nplt.figure()\nplt.hist(tips['total_bill'].dropna(), bins=20)\nplt.title('Histogram: total_bill')\nplt.xlabel('total_bill')\nplt.ylabel('Frequency')\nplt.show()", "outputs": [], "execution_count": null}, {"cell_type": "code", "metadata": {}, "source": "# Boxplot: tip by day\nplt.figure()\ndata = [tips.loc[tips['day']==d, 'tip'].dropna().values for d in tips['day'].cat.categories]\nplt.boxplot(data, labels=list(tips['day'].cat.categories))\nplt.title('Boxplot: tip by day')\nplt.xlabel('day')\nplt.ylabel('tip')\nplt.show()", "outputs": [], "execution_count": null}, {"cell_type": "code", "metadata": {}, "source": "# Scatter: total_bill vs tip (marker size reflects party size)\nplt.figure()\nplt.scatter(tips['total_bill'], tips['tip'], s=tips['size']*10, alpha=0.6)\nplt.title('Scatter: total_bill vs tip')\nplt.xlabel('total_bill')\nplt.ylabel('tip')\nplt.show()", "outputs": [], "execution_count": null}, {"cell_type": "code", "metadata": {}, "source": "# Bar chart: average tip_pct by day\navg_tip_pct = tips.groupby('day')['tip_pct'].mean()\nplt.figure()\nplt.bar(avg_tip_pct.index.astype(str), avg_tip_pct.values)\nplt.title('Average tip_pct by day')\nplt.xlabel('day')\nplt.ylabel('mean tip_pct')\nplt.show()", "outputs": [], "execution_count": null}, {"cell_type": "markdown", "metadata": {}, "source": "### \u2705 Exercise 4\n1. Create a scatter plot of `total_bill` vs `tip_pct`.  \n2. Create a bar chart of **median** `total_bill` by `time`."}, {"cell_type": "code", "metadata": {}, "source": "# YOUR WORK: Exercise 4\n# 1) Scatter\n# plt.figure()\n# plt.scatter(...)\n# plt.title('...')\n# plt.xlabel('...'); plt.ylabel('...'); plt.show()\n\n# 2) Bar (median by time)\n# med = ...\n# plt.figure()\n# plt.bar(...)\n# plt.title('...')\n# plt.xlabel('...'); plt.ylabel('...'); plt.show()", "outputs": [], "execution_count": null}, {"cell_type": "code", "metadata": {}, "source": "# Solution: Exercise 4\nplt.figure()\nplt.scatter(tips['total_bill'], tips['tip_pct'])\nplt.title('Scatter: total_bill vs tip_pct')\nplt.xlabel('total_bill'); plt.ylabel('tip_pct'); plt.show()\n\nmed = tips.groupby('time')['total_bill'].median()\nplt.figure()\nplt.bar(med.index.astype(str), med.values)\nplt.title('Median total_bill by time')\nplt.xlabel('time'); plt.ylabel('median total_bill'); plt.show()", "outputs": [], "execution_count": null}, {"cell_type": "markdown", "metadata": {}, "source": "---\n## 5) Grouping & Merging (20m)\n\n- Groupby and multiple aggregations (`.agg`)\n- Custom aggregations\n- Merge with a lookup table"}, {"cell_type": "code", "metadata": {}, "source": "# Grouping with multiple aggregations\ng = (tips\n     .groupby(['day','time'])\n     .agg(\n         count=('total_bill','size'),\n         avg_bill=('total_bill','mean'),\n         avg_tip=('tip','mean'),\n         avg_tip_pct=('tip_pct','mean')\n     )\n    )\ng.head()", "outputs": [], "execution_count": null}, {"cell_type": "code", "metadata": {}, "source": "# Custom aggregation via apply\ndef pct_above_20(s):\n    return (s > 0.20).mean()\n\ncustom = tips.groupby('day')['tip_pct'].apply(pct_above_20)\ncustom", "outputs": [], "execution_count": null}, {"cell_type": "code", "metadata": {}, "source": "# Create a lookup table and merge (e.g., weekend flag)\nday_lookup = pd.DataFrame({\n    'day':['Thur','Fri','Sat','Sun'],\n    'is_weekend':[False, False, True, True]\n})\n\ntips_merge = tips.merge(day_lookup, on='day', how='left')\ntips_merge[['day','is_weekend']].drop_duplicates().sort_values('day')", "outputs": [], "execution_count": null}, {"cell_type": "markdown", "metadata": {}, "source": "### \u2705 Exercise 5\n1. Compute **total revenue** (`total_bill.sum()`) and **total tips** (`tip.sum()`) by `smoker` and `sex`.  \n2. Merge `tips` with a small table mapping `time` \u2192 `meal_code` (Lunch\u2192L, Dinner\u2192D). Show distinct pairs."}, {"cell_type": "code", "metadata": {}, "source": "# YOUR WORK: Exercise 5\n# part1 = ...\n# part2 = ...", "outputs": [], "execution_count": null}, {"cell_type": "code", "metadata": {}, "source": "# Solution: Exercise 5\npart1 = tips.groupby(['smoker','sex']).agg(total_revenue=('total_bill','sum'),\n                                           total_tips=('tip','sum'))\ndisplay(part1)\n\ntime_map = pd.DataFrame({'time':['Lunch','Dinner'], 'meal_code':['L','D']})\npart2 = tips.merge(time_map, on='time', how='left')\ndisplay(part2[['time','meal_code']].drop_duplicates())", "outputs": [], "execution_count": null}, {"cell_type": "markdown", "metadata": {}, "source": "---\n## 6) Reshaping & Pivoting (15m)\n\n- `pivot_table` for summarised 2D tables\n- `stack` / `unstack`\n- `melt` to go long\u2011format"}, {"cell_type": "code", "metadata": {}, "source": "# Pivot: mean tip_pct by day (rows) and time (columns)\npiv = tips.pivot_table(index='day', columns='time', values='tip_pct', aggfunc='mean')\npiv", "outputs": [], "execution_count": null}, {"cell_type": "code", "metadata": {}, "source": "# Stack/Unstack demo\nstacked = piv.stack()     # (day,time) index\nunstacked = stacked.unstack()\nunstacked", "outputs": [], "execution_count": null}, {"cell_type": "code", "metadata": {}, "source": "# Melt: wide -> long\nlong = tips[['day','time','total_bill','tip']].melt(id_vars=['day','time'],\n                                                    var_name='metric',\n                                                    value_name='value')\nlong.head()", "outputs": [], "execution_count": null}, {"cell_type": "markdown", "metadata": {}, "source": "### \u2705 Exercise 6\n1. Build a pivot table of **mean total_bill** (values) by `size` (rows) and `day` (columns).  \n2. Convert it back to long format with `melt` (id_vars should include `size`)."}, {"cell_type": "code", "metadata": {}, "source": "# YOUR WORK: Exercise 6\n# piv2 = ...\n# long2 = ...\n# display(piv2); display(long2.head())", "outputs": [], "execution_count": null}, {"cell_type": "code", "metadata": {}, "source": "# Solution: Exercise 6\npiv2 = tips.pivot_table(index='size', columns='day', values='total_bill', aggfunc='mean')\nlong2 = piv2.reset_index().melt(id_vars=['size'], var_name='day', value_name='mean_total_bill')\ndisplay(piv2); display(long2.head())", "outputs": [], "execution_count": null}, {"cell_type": "markdown", "metadata": {}, "source": "---\n## 7) Mini\u2011Project: When are tips the most generous? (5\u201310m)\n\nGoal: Find the **day/time** combinations with the **highest average `tip_pct`** and visualise the matrix.\n\nSteps:\n1. Compute `piv` of mean `tip_pct` by `day` and `time`.  \n2. Show top combinations.  \n3. Visualise with an image plot (`imshow`)."}, {"cell_type": "code", "metadata": {}, "source": "# 1) We already computed 'piv' above. Recompute for clarity:\npiv = tips.pivot_table(index='day', columns='time', values='tip_pct', aggfunc='mean')\n\n# 2) Top combos\nprint(piv.stack().sort_values(ascending=False).head(5))\n\n# 3) Visualise\nplt.figure()\nplt.imshow(piv.values, aspect='auto')\nplt.title('Mean tip_pct by day & time')\nplt.xlabel('time')\nplt.ylabel('day')\nplt.xticks(ticks=range(len(piv.columns)), labels=piv.columns.astype(str))\nplt.yticks(ticks=range(len(piv.index)), labels=piv.index.astype(str))\nplt.colorbar()\nplt.show()", "outputs": [], "execution_count": null}, {"cell_type": "markdown", "metadata": {}, "source": "---\n## Wrap\u2011Up & Next Steps\n\n**You covered:** importing, selecting, filtering, sorting, adding columns; cleaning; missing data; analysis; plotting; grouping; merging; pivoting and reshaping.\n\n**Next:** try pandas with your own dataset (CSV/Excel/SQL), practise joins, window functions (`.rolling`, `.expanding`), and time\u2011series (`DatetimeIndex`).\n\n---\n\n### Appendix: Colab tips\n- Upload a local file:  \n  ```python\n  from google.colab import files\n  up = files.upload()     # pick a file, then:\n  import io\n  import pandas as pd\n  df = pd.read_csv(io.BytesIO(up['your_file.csv']))\n  ```\n- Mount Google Drive:  \n  ```python\n  from google.colab import drive\n  drive.mount('/content/drive')\n  # then: pd.read_csv('/content/drive/MyDrive/path/to/file.csv')\n  ```"}], "metadata": {"colab": {"name": "Pandas in Google Colab \u2014 2\u2011Hour Tips Dataset Tutorial"}, "kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"name": "python", "pygments_lexer": "ipython3"}}, "nbformat": 4, "nbformat_minor": 5}