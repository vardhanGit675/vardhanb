{"cells":[{"cell_type":"code","execution_count":29,"metadata":{"executionInfo":{"elapsed":5,"status":"ok","timestamp":1758054331435,"user":{"displayName":"naga vardhan chebrolu | AP23110010042","userId":"02124887627493061810"},"user_tz":-330},"id":"qTcv4GiB6aSv"},"outputs":[],"source":["import numpy as np\n","import pandas as pd\n","import os\n","from pathlib import Path\n","from sklearn.datasets import load_breast_cancer\n","from sklearn.model_selection import train_test_split, cross_validate, ShuffleSplit\n","from sklearn.metrics import accuracy_score\n","from sklearn.preprocessing import OneHotEncoder, StandardScaler, MinMaxScaler\n","from sklearn.compose import ColumnTransformer\n","from sklearn.pipeline import Pipeline\n","from sklearn.impute import SimpleImputer\n","from sklearn.feature_selection import SelectKBest, chi2\n","from sklearn.linear_model import LogisticRegression, LinearRegression\n","from sklearn.utils import shuffle\n","from sklearn.dummy import DummyRegressor\n","from sklearn.svm import SVC\n","from sklearn.linear_model import SGDClassifier\n","from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix,roc_curve, roc_auc_score,log_loss, classification_report,r2_score\n","from sklearn.preprocessing import LabelEncoder\n","import matplotlib.pyplot as plt"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"id":"W3Dv4gSB6jgm"},"outputs":[{"name":"stdout","output_type":"stream","text":["Dataset URL: https://www.kaggle.com/datasets/uciml/breast-cancer-wisconsin-data\n","License(s): CC-BY-NC-SA-4.0\n","breast-cancer-wisconsin-data.zip: Skipping, found more recently modified local copy (use --force to force download)\n","Archive:  breast-cancer-wisconsin-data.zip\n","replace data.csv? [y]es, [n]o, [A]ll, [N]one, [r]ename: "]}],"source":["os.environ['KAGGLE_USERNAME'] = 'vardhan.chebrolu'\n","os.environ['KAGGLE_KEY'] = '7ef605fc8dba5425d6965fbd4c8fbe1f'\n","! kaggle datasets download -d uciml/breast-cancer-wisconsin-data\n","! unzip breast-cancer-wisconsin-data.zip"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"MDHCCuTt7FD0"},"outputs":[],"source":["df=pd.read_csv('/content/data.csv')\n","df.head()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"k4Ub9oJi7XGP"},"outputs":[],"source":["df.isna()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"leC9Vpfd7nFm"},"outputs":[],"source":["df['diagnosis'].value_counts()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_5SK_QdQ7smm"},"outputs":[],"source":["from sklearn.preprocessing import StandardScaler, LabelEncoder\n","from sklearn.compose import ColumnTransformer\n","\n","X = df.drop(['diagnosis', 'id', 'Unnamed: 32'], axis=1)\n","y = df['diagnosis']\n","\n","label_encoder = LabelEncoder()\n","y_encoded = label_encoder.fit_transform(y)\n","\n","numerical_features = X.columns.tolist()\n","\n","preprocessor = ColumnTransformer(\n","    transformers=[\n","        ('num', StandardScaler(), numerical_features)\n","    ],\n","    remainder='passthrough'\n",")\n","\n","features_scaled = preprocessor.fit_transform(X)\n","\n","print(\"Shape of original features:\", X.shape)\n","print(\"Shape after preprocessing:\", features_scaled.shape)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ydtIgtrm9HIa"},"outputs":[],"source":["ng = np.random.default_rng(7)\n","dataset = pd.read_csv('/content/data.csv')\n","dataset.head()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"qItZ_yhm8M6p"},"outputs":[],"source":["feature_columns = ['radius_mean', 'area_mean', 'area_worst']\n","x = dataset[feature_columns]\n","y = dataset['diagnosis']\n","x, y = shuffle(x, y, random_state=42)\n","features = dataset[feature_columns]\n","labels = dataset['diagnosis']\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Sv5Kqegd9we0"},"outputs":[],"source":["features, labels = shuffle(features, labels, random_state=42)\n","train_features,test_features,train_labels,test_labels=train_test_split(features,labels,test_size=0.2,random_state=42)\n","shuffle_split_cv = ShuffleSplit(n_splits=10, test_size=0.2, random_state=42)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"VwgaX9-k96oT"},"outputs":[],"source":["log_reg=LogisticRegression(max_iter=1000,random_state=42)\n","log_reg_pipeline = Pipeline([(\"feature_scaling\", StandardScaler()), (\"logistic_regression\", LogisticRegression())])\n","log_reg_cv_results = cross_validate(log_reg_pipeline, train_features, train_labels, cv=shuffle_split_cv, scoring=\"accuracy\")\n","log_reg_scores = pd.Series(log_reg_cv_results['test_score'], name=\"log_reg_accuracy\")\n","log_reg_pipeline.fit(train_features, train_labels)\n","labels_pred = log_reg_pipeline.predict(test_features)\n","train_accuracy = accuracy_score(train_labels, log_reg_pipeline.predict(train_features))\n","test_accuracy = accuracy_score(test_labels, labels_pred)\n","\n","find_accu= accuracy_score(test_labels,labels_pred)\n","find_prec= precision_score(test_labels,labels_pred, pos_label='M')\n","find_recall= recall_score(test_labels,labels_pred, pos_label='M')\n","find_f1= f1_score(test_labels,labels_pred, pos_label='M')\n","print(\"accuracy\",find_accu)\n","print(\"precision\",find_prec)\n","print(\"recall\",find_recall)\n","print(\"f1\",find_f1)\n","print(\"\")\n","\n","print(\"trained accuracy\",train_accuracy)\n","print(\"test accuracy\",test_accuracy)\n","print(\"\")\n","if train_accuracy\u003etest_accuracy+0.05:\n","  print(\"Overfitting\")\n","elif train_accuracy\u003c0.7 and test_accuracy\u003c0.7:\n","  print(\"underfitting\")\n","else:\n","  print(\"model is good\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"AZ5atX6E98JP"},"outputs":[],"source":["lin_reg = LinearRegression()\n","train_features, test_features, train_labels_encoded, test_labels_encoded = train_test_split(features, y_encoded, test_size=0.2, random_state=42)\n","lin_reg_pipeline = Pipeline([(\"linear_regression\", LinearRegression())])\n","lin_reg_cv_results = cross_validate(lin_reg_pipeline, train_features, train_labels_encoded, cv=shuffle_split_cv, scoring=\"r2\")\n","lin_reg_scores = pd.Series(lin_reg_cv_results['test_score'], name=\"lin_reg_r2\")\n","lin_reg_pipeline.fit(train_features, train_labels_encoded)\n","labels_pred_encoded = lin_reg_pipeline.predict(test_features)\n","train_r2 = r2_score(train_labels_encoded, lin_reg_pipeline.predict(train_features))\n","test_r2 = r2_score(test_labels_encoded, labels_pred_encoded)\n","print(\"train R2:\", train_r2)\n","print(\"test R2:\", test_r2)\n","print(\"\")\n","if train_r2 \u003c 0.7 and test_r2 \u003c 0.7:\n","  print(\"underfitting\")\n","else:\n","  print(\"model fit is moderate to good\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"UlRcrlalDgxz"},"outputs":[],"source":["selected_features = ['radius_mean', 'area_mean', 'area_worst']\n","X = x[selected_features]\n","y = y\n","le = LabelEncoder()\n","y_encoded = le.fit_transform(y)\n","\n","print(\"Classes:\", le.classes_)\n","print(\"Encoded target (first 10):\", y_encoded[:10])\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"AH1Wt5CiDaoA"},"outputs":[],"source":["scaler = StandardScaler()\n","features_scaled = scaler.fit_transform(features)\n","\n","model = LogisticRegression(max_iter=1000, solver='lbfgs')\n","model.fit(features_scaled, y)\n","\n","probs = model.predict_proba(features_scaled)[:, 1]\n","loss = log_loss(y, probs)\n","final_weights = model.coef_[0]\n","final_bias = model.intercept_[0]\n","\n","print(\"Forward Pass (first 5 probs):\", probs[:5])\n","print(\"Backward Pass (final loss):\", loss)\n","print(\"Final Weights shape:\", final_weights.shape)\n","print(\"Final Bias:\", final_bias)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"BhI9utxIBXhI"},"outputs":[],"source":["loss=log_loss(test_labels,labels_pred_encoded)\n","print(\"loss\",loss)\n","r2=r2_score(test_labels_encoded,labels_pred_encoded)\n","print(\"r2\",r2)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"meaomQAqIO7U"},"outputs":[],"source":["from sklearn.linear_model import LinearRegression\n","from sklearn.metrics import r2_score, mean_squared_error\n","\n","# --- Simple Linear Regression ---\n","lin_reg = LinearRegression()\n","\n","# Fit the model\n","lin_reg.fit(train_features, train_labels_encoded)\n","\n","# Predict on train and test data\n","train_pred = lin_reg.predict(train_features)\n","test_pred = lin_reg.predict(test_features)\n","\n","# Evaluate performance\n","train_r2 = r2_score(train_labels_encoded, train_pred)\n","test_r2 = r2_score(test_labels_encoded, test_pred)\n","\n","print(\"Simple Linear Regression Results\")\n","print(\"Train R²:\", train_r2)\n","print(\"Test R²:\", test_r2)\n","print(\"Train MSE:\", mean_squared_error(train_labels_encoded, train_pred))\n","print(\"Test MSE:\", mean_squared_error(test_labels_encoded, test_pred))\n","\n","# Check for underfitting/overfitting\n","if train_r2 \u003c 0.7 and test_r2 \u003c 0.7:\n","    print(\"Model is Underfitting\")\n","elif abs(train_r2 - test_r2) \u003e 0.2:\n","    print(\"Model may be Overfitting\")\n","else:\n","    print(\"Model fit is good\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"z7rRa6j7Jb0b"},"outputs":[],"source":["from sklearn.linear_model import LinearRegression\n","from sklearn.metrics import r2_score, mean_squared_error\n","from sklearn.model_selection import train_test_split\n","from sklearn.utils import shuffle\n","\n","# Shuffle and split\n","features, labels = shuffle(features, labels, random_state=42)\n","train_features, test_features, train_labels_encoded, test_labels_encoded = train_test_split(\n","    features, y_encoded, test_size=0.2, random_state=42\n",")\n","\n","# --- Multi Linear Regression ---\n","multi_lin_reg = LinearRegression()\n","multi_lin_reg.fit(train_features, train_labels_encoded)\n","\n","# Predictions\n","train_pred = multi_lin_reg.predict(train_features)\n","test_pred = multi_lin_reg.predict(test_features)\n","\n","# Evaluation\n","train_r2 = r2_score(train_labels_encoded, train_pred)\n","test_r2 = r2_score(test_labels_encoded, test_pred)\n","\n","print(\"Multi Linear Regression Results\")\n","print(\"Train R²:\", train_r2)\n","print(\"Test R²:\", test_r2)\n","print(\"Train MSE:\", mean_squared_error(train_labels_encoded, train_pred))\n","print(\"Test MSE:\", mean_squared_error(test_labels_encoded, test_pred))\n","\n","# Check for underfitting / overfitting\n","if train_r2 \u003c 0.7 and test_r2 \u003c 0.7:\n","    print(\"Model is Underfitting\")\n","elif abs(train_r2 - test_r2) \u003e 0.2:\n","    print(\"Model may be Overfitting\")\n","else:\n","    print(\"Model fit is good\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"nu63s62TIa19"},"outputs":[],"source":["from sklearn.preprocessing import PolynomialFeatures\n","from sklearn.linear_model import LinearRegression\n","from sklearn.metrics import r2_score, mean_squared_error\n","\n","# --- Polynomial Linear Regression ---\n","# Degree of polynomial (you can tune this, e.g., 2 or 3)\n","poly = PolynomialFeatures(degree=2, include_bias=False)\n","\n","# Transform features into polynomial form\n","train_features_poly = poly.fit_transform(train_features)\n","test_features_poly = poly.transform(test_features)\n","\n","# Train Linear Regression on polynomial features\n","poly_reg = LinearRegression()\n","poly_reg.fit(train_features_poly, train_labels_encoded)\n","\n","# Predictions\n","train_pred_poly = poly_reg.predict(train_features_poly)\n","test_pred_poly = poly_reg.predict(test_features_poly)\n","\n","# Evaluate performance\n","train_r2_poly = r2_score(train_labels_encoded, train_pred_poly)\n","test_r2_poly = r2_score(test_labels_encoded, test_pred_poly)\n","\n","print(\"Polynomial Linear Regression Results (degree=2)\")\n","print(\"Train R²:\", train_r2_poly)\n","print(\"Test R²:\", test_r2_poly)\n","print(\"Train MSE:\", mean_squared_error(train_labels_encoded, train_pred_poly))\n","print(\"Test MSE:\", mean_squared_error(test_labels_encoded, test_pred_poly))\n","\n","# Overfitting / underfitting check\n","if train_r2_poly \u003c 0.7 and test_r2_poly \u003c 0.7:\n","    print(\"Model is Underfitting\")\n","elif abs(train_r2_poly - test_r2_poly) \u003e 0.2:\n","    print(\"Model may be Overfitting\")\n","else:\n","    print(\"Model fit is good\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"uTNjwNxeLyBd"},"outputs":[],"source":["if 'id' in dataset.columns:\n","    data = dataset.drop(columns=['id'])\n","\n","# Encode target: Malignant=1, Benign=0\n","data['diagnosis'] = data['diagnosis'].map({'M': 1, 'B': 0})\n","\n","# Features and target\n","X = data.drop(columns=['diagnosis'])\n","y = data['diagnosis']\n","\n","# Train-test split\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n","\n","# Try with different numbers of features (d)\n","for d in range(1, 6):  # d = 1 to 5\n","    selected_features = X_train.iloc[:, :d]   # take first d features\n","    model = LinearRegression()\n","    model.fit(selected_features, y_train)\n","    y_pred = model.predict(X_test.iloc[:, :d])\n","    r2 = r2_score(y_test, y_pred)\n","    print(f\"d={d}, R2 Score={r2:.4f}\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"N0YxgqslM8xl"},"outputs":[],"source":["if 'id' in data.columns:\n","    data = data.drop(columns=['id'])\n","\n","# Encode target: Malignant=1, Benign=0\n","data['diagnosis'] = data['diagnosis'].map({'M': 1, 'B': 0})\n","\n","# Features and labels\n","features = data.drop(columns=['diagnosis'])\n","labels = data['diagnosis']\n","\n","# Encode labels if needed\n","le = LabelEncoder()\n","y_encoded = le.fit_transform(labels)\n","\n","# Shuffle dataset\n","features, labels = shuffle(features, labels, random_state=42)\n","\n","# Train-test split\n","train_features, test_features, train_labels_encoded, test_labels_encoded = train_test_split(\n","    features, y_encoded, test_size=0.2, random_state=42\n",")\n","\n","# Loop for d = 1 to 5\n","for d in range(1, 6):\n","    # Select first d features\n","    train_d = train_features.iloc[:, :d]\n","    test_d = test_features.iloc[:, :d]\n","\n","    # Train linear regression\n","    model = LinearRegression()\n","    model.fit(train_d, train_labels_encoded)\n","    y_pred = model.predict(test_d)\n","\n","    # R² score\n","    r2 = r2_score(test_labels_encoded, y_pred)\n","\n","    # Eigenvalues \u0026 condition index\n","    cov_matrix = np.cov(train_d, rowvar=False)\n","    eigenvalues, _ = np.linalg.eig(cov_matrix)\n","    eigenvalues = np.real(eigenvalues)  # handle tiny imaginary parts\n","\n","    max_eig = np.max(eigenvalues)\n","    min_eig = np.min(eigenvalues[eigenvalues \u003e 0]) if np.any(eigenvalues \u003e 0) else 1e-10\n","    condition_index = np.sqrt(max_eig / min_eig)\n","\n","    print(f\"d={d}, R²={r2:.4f}, λ={eigenvalues.round(2)}, η={condition_index:.2f}\")"]}],"metadata":{"colab":{"authorship_tag":"ABX9TyNasbAkmYVoCai48kNlOFbs","name":"","provenance":[{"file_id":"1XygXc6ja7TAI-muel46WmtPT3O_YsB_k","timestamp":1757533345449}],"version":""},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}